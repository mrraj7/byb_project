{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqt_yzRy16Wj"
   },
   "source": [
    "## Task\n",
    "\n",
    "In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "id": "vBP3WN2O16Wp"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import chardet\n",
    "from datetime import date\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up store_income_data.csv\n",
    "df = pd.read_csv('store_income_data_task.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItqLwumA16Wr"
   },
   "source": [
    "1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "sLkzt4Hr16Wr"
   },
   "outputs": [],
   "source": [
    "# Convert to lower case\n",
    "df['country'] = df['country'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing white spaces\n",
    "df['country'] = df['country'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_email</th>\n",
       "      <th>department</th>\n",
       "      <th>income</th>\n",
       "      <th>date_measured</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FIRST REPUBLIC BANK</td>\n",
       "      <td>ecanadine3@fc2.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$8928350.04</td>\n",
       "      <td>8-5-2006</td>\n",
       "      <td>britain/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Auburn National Bancorporation, Inc.</td>\n",
       "      <td>ccaldeyroux5@dion.ne.jp</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>$69798987.04</td>\n",
       "      <td>19-9-1999</td>\n",
       "      <td>u.k.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Interlink Electronics, Inc.</td>\n",
       "      <td>orodenborch6@skyrock.com</td>\n",
       "      <td>Garden</td>\n",
       "      <td>$22521052.79</td>\n",
       "      <td>8-6-2001</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Synopsys, Inc.</td>\n",
       "      <td>lcancellieri9@tmall.com</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>$44091294.62</td>\n",
       "      <td>11-7-2006</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>New Home Company Inc. (The)</td>\n",
       "      <td>nhinchcliffef@whitehouse.gov</td>\n",
       "      <td>Shoes</td>\n",
       "      <td>$90808764.99</td>\n",
       "      <td>21-4-1993</td>\n",
       "      <td>britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>988</td>\n",
       "      <td>Ares Dynamic Credit Allocation Fund, Inc.</td>\n",
       "      <td>fbrocklebankrf@sitemeter.com</td>\n",
       "      <td>Health</td>\n",
       "      <td>$34762898.80</td>\n",
       "      <td>15-12-1989</td>\n",
       "      <td>sa/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>990</td>\n",
       "      <td>Madison Covered Call &amp; Equity Strategy Fund</td>\n",
       "      <td>nbaikerh@list-manage.com</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>$85704421.13</td>\n",
       "      <td>16-7-1993</td>\n",
       "      <td>uk.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>992</td>\n",
       "      <td>Atlantic Capital Bancshares, Inc.</td>\n",
       "      <td>mgribbellrj@symantec.com</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>$83355366.27</td>\n",
       "      <td>13-4-2001</td>\n",
       "      <td>s.a..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>Columbia Sportswear Company</td>\n",
       "      <td>cschooleyrn@sohu.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$52593924.99</td>\n",
       "      <td>7-10-2005</td>\n",
       "      <td>s. africasouth africa/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>Tortoise Energy Infrastructure Corporation</td>\n",
       "      <td>cbeardshallrp@ow.ly</td>\n",
       "      <td>Health</td>\n",
       "      <td>$1697293.64</td>\n",
       "      <td>25-4-2009</td>\n",
       "      <td>united states of america</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>384 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                   store_name  \\\n",
       "3      4                          FIRST REPUBLIC BANK   \n",
       "5      6         Auburn National Bancorporation, Inc.   \n",
       "6      7                  Interlink Electronics, Inc.   \n",
       "9     10                               Synopsys, Inc.   \n",
       "15    16                  New Home Company Inc. (The)   \n",
       "..   ...                                          ...   \n",
       "987  988    Ares Dynamic Credit Allocation Fund, Inc.   \n",
       "989  990  Madison Covered Call & Equity Strategy Fund   \n",
       "991  992            Atlantic Capital Bancshares, Inc.   \n",
       "995  996                  Columbia Sportswear Company   \n",
       "997  998   Tortoise Energy Infrastructure Corporation   \n",
       "\n",
       "                      store_email   department        income date_measured  \\\n",
       "3              ecanadine3@fc2.com   Automotive   $8928350.04      8-5-2006   \n",
       "5         ccaldeyroux5@dion.ne.jp      Grocery  $69798987.04     19-9-1999   \n",
       "6        orodenborch6@skyrock.com       Garden  $22521052.79      8-6-2001   \n",
       "9         lcancellieri9@tmall.com  Electronics  $44091294.62     11-7-2006   \n",
       "15   nhinchcliffef@whitehouse.gov        Shoes  $90808764.99     21-4-1993   \n",
       "..                            ...          ...           ...           ...   \n",
       "987  fbrocklebankrf@sitemeter.com       Health  $34762898.80    15-12-1989   \n",
       "989      nbaikerh@list-manage.com  Electronics  $85704421.13     16-7-1993   \n",
       "991      mgribbellrj@symantec.com     Clothing  $83355366.27     13-4-2001   \n",
       "995          cschooleyrn@sohu.com   Automotive  $52593924.99     7-10-2005   \n",
       "997           cbeardshallrp@ow.ly       Health   $1697293.64     25-4-2009   \n",
       "\n",
       "                      country  \n",
       "3                    britain/  \n",
       "5                        u.k.  \n",
       "6                          sa  \n",
       "9              united kingdom  \n",
       "15                    britain  \n",
       "..                        ...  \n",
       "987                       sa/  \n",
       "989                       uk.  \n",
       "991                     s.a..  \n",
       "995    s. africasouth africa/  \n",
       "997  united states of america  \n",
       "\n",
       "[384 rows x 7 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows having null values\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['united states/', 'britain', 'united states', 'britain/',\n",
       "       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n",
       "       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n",
       "       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n",
       "       'america.', 's.a..', 'united states of america.',\n",
       "       'united states of america/', 'united states.',\n",
       "       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n",
       "       's. africasouth africa/', 'united kingdom/',\n",
       "       's. africasouth africa.', '.'], dtype=object)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 unique countries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['united states/', 'britain', 'united states', 'britain/',\n",
       "       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n",
       "       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n",
       "       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n",
       "       'america.', 's.a..', 'united states of america.',\n",
       "       'united states of america/', 'united states.',\n",
       "       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n",
       "       's. africasouth africa/', 'united kingdom/',\n",
       "       's. africasouth africa.', '.'], dtype=object)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us view the data\n",
    "countries = df['country'].unique()\n",
    "print(f\"There are {len(countries)} unique countries\")\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_email</th>\n",
       "      <th>department</th>\n",
       "      <th>income</th>\n",
       "      <th>date_measured</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cullen/Frost Bankers, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>$54438554.24</td>\n",
       "      <td>4-2-2006</td>\n",
       "      <td>united states/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nordson Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools</td>\n",
       "      <td>$41744177.01</td>\n",
       "      <td>4-1-2006</td>\n",
       "      <td>britain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stag Industrial, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>$36152340.34</td>\n",
       "      <td>12-9-2003</td>\n",
       "      <td>united states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FIRST REPUBLIC BANK</td>\n",
       "      <td>ecanadine3@fc2.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$8928350.04</td>\n",
       "      <td>8-5-2006</td>\n",
       "      <td>britain/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercantile Bank Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>$33552742.32</td>\n",
       "      <td>21-1-1973</td>\n",
       "      <td>united kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   store_name         store_email  department  \\\n",
       "0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n",
       "1   2          Nordson Corporation                 NaN       Tools   \n",
       "2   3        Stag Industrial, Inc.                 NaN      Beauty   \n",
       "3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n",
       "4   5  Mercantile Bank Corporation                 NaN        Baby   \n",
       "\n",
       "         income date_measured         country  \n",
       "0  $54438554.24      4-2-2006  united states/  \n",
       "1  $41744177.01      4-1-2006         britain  \n",
       "2  $36152340.34     12-9-2003   united states  \n",
       "3   $8928350.04      8-5-2006        britain/  \n",
       "4  $33552742.32     21-1-1973  united kingdom  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 10 closest matches to \"united kingdom\"\n",
    "matches = fuzzywuzzy.process.extract(\"uk\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# Inspect matches\n",
    "matches\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace rows in the provided column of the provided DataFrame\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 90):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # Get the top 10 closest matches to our input string\n",
    "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "    # Only get matches with a ratio > 90\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # Get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # Replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # Let us know when the function is done\n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# Replace the country column value with appropriate matched country names\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united kingdom\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"england\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united states\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united states of america\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"america\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"south africa\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"s. africasouth africa\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"s.a\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"uk\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"u.k\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"britain\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6dcDc4P16Ws"
   },
   "source": [
    "2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "id": "qeV3CxMR16Ws"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17 unique countries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['united states', 'britain', 'united kingdom', 'u.k', 'sa',\n",
       "       'america', nan, 's.a', 'england', 'uk', 'sa.', '',\n",
       "       'united states of america', 'sa/', 's. africasouth africa', '/',\n",
       "       '.'], dtype=object)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'country' column\n",
    "countries = df['country'].unique()\n",
    "\n",
    "print(f\"There are {len(countries)} unique countries\")\n",
    "countries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('britain', 'united kingdom', inplace=True)\n",
    "df.replace('u.k', 'united kingdom', inplace=True)\n",
    "df.replace('uk', 'united kingdom', inplace=True)\n",
    "df.replace('england', 'united kingdom', inplace=True)\n",
    "df.replace('united states of america', 'united states', inplace=True)\n",
    "df.replace('america', 'united states', inplace=True)\n",
    "df.replace('sa', 'south africa', inplace=True)\n",
    "df.replace('s.a', 'south africa', inplace=True)\n",
    "df.replace('sa.', 'south africa', inplace=True)\n",
    "df.replace('s. africasouth africa', 'south africa', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 unique countries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['united states', 'united kingdom', 'south africa', nan, '', 'sa/',\n",
       "       '/', '.'], dtype=object)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'country' column\n",
    "countries = df['country'].unique()\n",
    "\n",
    "print(f\"There are {len(countries)} unique countries\")\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJZDMTwP16Ws"
   },
   "source": [
    "3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column and assign 'date_measured'\n",
    "df['days_ago'] = df['date_measured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-04-29'"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.datetime.today()).split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 4, 29)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2024, 4, 29)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_parsed'] = pd.to_datetime(df['date_measured'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_name</th>\n",
       "      <th>store_email</th>\n",
       "      <th>department</th>\n",
       "      <th>income</th>\n",
       "      <th>date_measured</th>\n",
       "      <th>country</th>\n",
       "      <th>days_ago</th>\n",
       "      <th>date_parsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cullen/Frost Bankers, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>$54438554.24</td>\n",
       "      <td>4-2-2006</td>\n",
       "      <td>united states</td>\n",
       "      <td>4-2-2006</td>\n",
       "      <td>2006-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nordson Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tools</td>\n",
       "      <td>$41744177.01</td>\n",
       "      <td>4-1-2006</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>4-1-2006</td>\n",
       "      <td>2006-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stag Industrial, Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>$36152340.34</td>\n",
       "      <td>12-9-2003</td>\n",
       "      <td>united states</td>\n",
       "      <td>12-9-2003</td>\n",
       "      <td>2003-09-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>FIRST REPUBLIC BANK</td>\n",
       "      <td>ecanadine3@fc2.com</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>$8928350.04</td>\n",
       "      <td>8-5-2006</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>8-5-2006</td>\n",
       "      <td>2006-05-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercantile Bank Corporation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Baby</td>\n",
       "      <td>$33552742.32</td>\n",
       "      <td>21-1-1973</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>21-1-1973</td>\n",
       "      <td>1973-01-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   store_name         store_email  department  \\\n",
       "0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n",
       "1   2          Nordson Corporation                 NaN       Tools   \n",
       "2   3        Stag Industrial, Inc.                 NaN      Beauty   \n",
       "3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n",
       "4   5  Mercantile Bank Corporation                 NaN        Baby   \n",
       "\n",
       "         income date_measured         country   days_ago date_parsed  \n",
       "0  $54438554.24      4-2-2006   united states   4-2-2006  2006-02-04  \n",
       "1  $41744177.01      4-1-2006  united kingdom   4-1-2006  2006-01-04  \n",
       "2  $36152340.34     12-9-2003   united states  12-9-2003  2003-09-12  \n",
       "3   $8928350.04      8-5-2006  united kingdom   8-5-2006  2006-05-08  \n",
       "4  $33552742.32     21-1-1973  united kingdom  21-1-1973  1973-01-21  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date_parsed'].dtype"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
